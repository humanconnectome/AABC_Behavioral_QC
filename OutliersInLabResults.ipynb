{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a808de6c-52d6-4cbc-b130-f554dd336ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load some libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from ccf.box import LifespanBox\n",
    "import yaml\n",
    "from functions import *\n",
    "from config import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469b8c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make interactive plots possible to plot\n",
    "pio.renderers.default = \"notebook+pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2991cd-f2c5-4dad-a65f-1b1ba15a0ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load aabc dataset\n",
    "config = LoadSettings()\n",
    "secret=pd.read_csv(config['config_files']['secrets'])\n",
    "#box = LifespanBox(cache=\"./tmp\")\n",
    "aabcarms = redjson(tok=secret.loc[secret.source=='aabcarms','api_key'].reset_index().drop(columns='index').api_key[0])\n",
    "aabc=getframe(struct=aabcarms,api_url=config['Redcap']['api_url10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517265b3-8b8d-4ee2-887b-7178aeb3af09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the dictionary downloaded from REDCap\n",
    "all_dict = pd.read_csv('AABC_REDCap_DataDictionary_2023-10-13.csv')\n",
    "\n",
    "#choose the variables only when form name is lab_results\n",
    "part_dict = all_dict[[\"Variable / Field Name\", \"Form Name\"]]\n",
    "part_dict = part_dict[part_dict['Form Name']==\"lab_results\"]\n",
    "\n",
    "#form a list of variables name\n",
    "vars_list = part_dict['Variable / Field Name'].tolist()\n",
    "#print(vars_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74d37b4-1a73-4023-b542-d43e276a6625",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the variables which are not in REDCap dataset\n",
    "elements_to_remove = ['cmp', 'lipid', 'hormones']\n",
    "vars_list = [elem for elem in vars_list if elem not in elements_to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077c7ecf-b2b8-454e-90c7-7978226752cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inlcude other necessary variables\n",
    "keepsies=['site','subject_id','sex','lab_results_complete','event_date']\n",
    "keepsies = keepsies + vars_list\n",
    "\n",
    "#function used to clean the dataframe \n",
    "def idvisits(aabcarmsdf,keepsies):\n",
    "    #idvisit=aabcarmsdf[keepsies].copy()\n",
    "    idvisit = aabcarmsdf[keepsies + ['redcap_event_name', 'study_id']].copy()\n",
    "    \n",
    "    #registers=idvisit.loc[idvisit.redcap_event_name.str.contains('register')][['subject_id','study_id','site']]\n",
    "    registers = idvisit.loc[idvisit['redcap_event_name'].str.contains('register'), ['subject_id', 'study_id', 'site', 'sex']]\n",
    "    \n",
    "    idvisit = pd.merge(registers, idvisit.drop(columns=['site']), on='study_id', how='right')\n",
    "    \n",
    "    idvisit=idvisit.rename(columns={'subject_id_x':'subject','subject_id_y':'subject_id','sex_x':'sex'})\n",
    "    \n",
    "    idvisit['redcap_event']=idvisit.replace({'redcap_event_name':\n",
    "                                           config['Redcap']['datasources']['aabcarms']['AABCeventmap']})['redcap_event_name']\n",
    "    \n",
    "    idvisit = idvisit.loc[~(idvisit.subject.astype(str).str.upper().str.contains('TEST'))]\n",
    "    #idvisit = idvisit.loc[~idvisit['subject'].astype(str).str.upper().contains('TEST')]\n",
    "    \n",
    "    return idvisit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da7af1d-567c-42fa-856c-406c188b34d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = idvisits(aabc,keepsies)\n",
    "#only choose subjects who visit and complete lab test\n",
    "records = records.loc[(records['redcap_event'] == \"V1\") | (records['redcap_event'] == \"V2\") | (records['redcap_event'] == \"V3\") ]\n",
    "records = records.loc[records['lab_results_complete'] == \"2\"]\n",
    "records = records.loc[records['bld_drawresults'] == \"1\"]\n",
    "records = records.drop(columns=['sex_y','subject_id'])\n",
    "records = records.reset_index(drop=True)\n",
    "#records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2ce9b0-629f-4b25-8efd-ca84c77cc942",
   "metadata": {},
   "outputs": [],
   "source": [
    "records.to_csv('records.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4891160a-2733-4957-b8bb-078ccd1fdcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions to classify numerical or catergorical columns\n",
    "def classify_column_types_with_heuristic(df, unique_threshold=10, unique_percentage=0.05):\n",
    "    numerical_columns = []\n",
    "    categorical_columns = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        # Attempt to convert columns with mixed types to numeric, replacing errors with NaN\n",
    "        if df[col].dtype == 'object':\n",
    "            try:\n",
    "                numeric_col = pd.to_numeric(df[col], errors='coerce')\n",
    "                if numeric_col.isnull().all():\n",
    "                    categorical_columns.append(col)\n",
    "                else:\n",
    "                    # Check unique values against thresholds to classify as numerical or categorical\n",
    "                    unique_values = numeric_col.nunique(dropna=True)\n",
    "                    if unique_values <= unique_threshold or unique_values / len(df) <= unique_percentage:\n",
    "                        categorical_columns.append(col)\n",
    "                    else:\n",
    "                        numerical_columns.append(col)\n",
    "            except ValueError:\n",
    "                categorical_columns.append(col)\n",
    "        elif df[col].dtype in ['int64', 'float64']:\n",
    "            # Check unique values against thresholds to classify as numerical or categorical\n",
    "            unique_values = df[col].nunique(dropna=True)\n",
    "            if unique_values <= unique_threshold or unique_values / len(df) <= unique_percentage:\n",
    "                categorical_columns.append(col)\n",
    "            else:\n",
    "                numerical_columns.append(col)\n",
    "        else:\n",
    "            categorical_columns.append(col)\n",
    "    \n",
    "    return numerical_columns, categorical_columns\n",
    "\n",
    "# Output the classification\n",
    "numerical_cols, categorical_cols = classify_column_types_with_heuristic(records)\n",
    "\n",
    "\n",
    "#numerical_cols, categorical_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0efc638",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols.remove(\"study_id\")\n",
    "num = records[numerical_cols]\n",
    "num = num.reset_index(drop=True)\n",
    "#num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13397e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "num.to_csv('numerical_cols.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19990672",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to handle special values and convert columns to numeric\n",
    "def preprocess_column(column):\n",
    "    # Handle \"<value\" and \">value\" by extracting \"value\"\n",
    "    column = column.replace({'<': '', '>': ''}, regex=True)\n",
    "    \n",
    "    # Convert \"ND\" to 0 (or another small number as required)\n",
    "    column = column.replace({'ND': 0})\n",
    "    \n",
    "    # Convert column to numeric, coercing errors to NaN (to find any non-converted values later if needed)\n",
    "    column = pd.to_numeric(column, errors='coerce')\n",
    "    return column\n",
    "\n",
    "# Apply preprocessing to each column\n",
    "for col in numerical_cols:\n",
    "    num[col] = preprocess_column(num[col])\n",
    "\n",
    "# Set the style of seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Plotting\n",
    "fig, axes = plt.subplots(len(numerical_cols), 1, figsize=(10, 5 * len(numerical_cols)))\n",
    "\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    sns.histplot(num[col], kde=True, ax=axes[i], binwidth=0.5)\n",
    "    axes[i].set_title(f'Distribution of {col}')\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31399151",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate mean and standard deviation for each column of interest\n",
    "for col in numerical_cols:\n",
    "    mean = num[col].mean()\n",
    "    std = num[col].std()\n",
    "    \n",
    "    # Define outliers as those outside Â±3 (4) standard deviations from the mean\n",
    "    num['outlier'] = ((num[col] < (mean - 4 * std)) | (num[col] > (mean + 4 * std)))\n",
    "    \n",
    "    # Violin Plot\n",
    "    fig_violin = px.violin(num, y=col, color='outlier', box=True, points=\"all\",\n",
    "                           hover_data=[num.index+2], title=f'Violin Plot of {col}')\n",
    "    fig_violin.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f2b91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming numerical_cols is your list of numerical column names\n",
    "num_all = numerical_cols.copy()  # Make a copy to avoid modifying the original list\n",
    "num_all.append('study_id')       # Append 'study_id' to the list\n",
    "num_all.append('subject')        # Append 'subject' to the list\n",
    "num_all.append('site')           # Append 'site' to the list\n",
    "num_all.append('event_date')     # Append 'event_date' to the list\n",
    "num_all.append('redcap_event')   # Append 'redcap_event' to the list\n",
    "num_outlier = records[num_all]\n",
    "num_outlier = num_outlier.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Function to handle special values and convert columns to numeric\n",
    "def preprocess_column1(column):\n",
    "    # Handle \"<value\" and \">value\" by extracting \"value\"\n",
    "    column = column.replace({'<': '', '>': ''}, regex=True)\n",
    "    \n",
    "    # Convert \"ND\" to 0 (or another small number as required)\n",
    "    column = column.replace({'ND': 0})\n",
    "    \n",
    "    # Convert column to numeric, coercing errors to NaN (to find any non-converted values later if needed)\n",
    "    #column = pd.to_numeric(column, errors='coerce')\n",
    "    return column\n",
    "\n",
    "# Apply preprocessing to each column\n",
    "for col in num_outlier.columns:\n",
    "    num_outlier[col] = preprocess_column1(num_outlier[col])\n",
    "\n",
    "#num_outlier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb7f33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to hold the outlier information\n",
    "outliers_info = []\n",
    "\n",
    "# Iterate through each numerical column to identify outliers\n",
    "for col in numerical_cols:\n",
    "    try:\n",
    "        num_outlier[col] = pd.to_numeric(num_outlier[col], errors='coerce')  # Ensure numeric, coerce errors to NaN\n",
    "        mean = num_outlier[col].mean()\n",
    "        std = num_outlier[col].std()\n",
    "\n",
    "        # Define outliers\n",
    "        is_outlier = ((num_outlier[col] < (mean - 4 * std)) | (num_outlier[col] > (mean + 4 * std)))\n",
    "        \n",
    "        # Filter outliers\n",
    "        outliers = num_outlier[is_outlier]\n",
    "        \n",
    "        # Append information to the outliers_info list\n",
    "        for index, row in outliers.iterrows():\n",
    "            reason = f\"{col}={row[col]}\"\n",
    "            outliers_info.append([row['subject'], row['redcap_event'], row['study_id'], row['site'], row['event_date'], reason])\n",
    "    except Exception as e:\n",
    "        # Skip columns that cannot be converted to numeric\n",
    "        print(f\"Skipping column {col} due to error: {e}\")\n",
    "\n",
    "# Convert the outliers_info list into a DataFrame\n",
    "outliers_df = pd.DataFrame(outliers_info, columns=['subject','redcap_event', 'study_id', 'site', 'event_date', 'reason'])\n",
    "\n",
    "# Group by 'study-id', 'subject', 'redcap_event' and merge 'reason' for the same subject\n",
    "outliers_df = outliers_df.groupby(['subject','redcap_event', 'study_id', 'site', 'event_date'])['reason'].apply(lambda x: '; '.join(x)).reset_index()\n",
    "\n",
    "# Adding \"lab results: \" prefix only once per grouped entry for tidiness\n",
    "outliers_df['reason'] = 'lab_results: ' + outliers_df['reason']\n",
    "\n",
    "outliers_df['datatype'] = 'REDCap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c41bfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02399511",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_df.to_csv('outliers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8686f234",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outliers_df.shape)\n",
    "print(len(outliers_df['subject'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ceebf4-a733-4cf2-be34-bb1cd4c7fb75",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#remove the variables which are not in REDCap dataset\n",
    "elements_to_remove1 = ['subject', 'lab_results_complete', 'event_date', 'bld_drawresults', 'ldl', 'ldl_notes', 'blood_notes', 'labs_returned', 'labs_returned_notreason', 'redcap_event_name']\n",
    "categorical_cols = [elem for elem in categorical_cols if elem not in elements_to_remove1]\n",
    "\n",
    "# Plot distributions for selected categorical columns\n",
    "fig, axs = plt.subplots(len(categorical_cols), 1, figsize=(10, len(categorical_cols)*4))\n",
    "\n",
    "for i, col in enumerate(categorical_cols):\n",
    "    sns.countplot(x=records[col], ax=axs[i])\n",
    "    axs[i].set_title(f'Count Plot of {col}')\n",
    "    axs[i].set_xlabel(col)\n",
    "    axs[i].set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AABC_env",
   "language": "python",
   "name": "aabc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
